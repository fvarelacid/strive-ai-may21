{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN From Scratch\n",
    "\n",
    "In this workbook we will guide you through the steps to implement KNN from scratch. Once this is done you'll implement you solution in a class that is tested with the knn_class_tester notebook.\n",
    "\n",
    "1. Use the ```make_blobs``` function from SKLearn to make a dataset to test your KNN functions.\n",
    "2. Create helper functions. These will be useful when you go to implement your class.\n",
    "    - Squaring the difference of two vectors.\n",
    "    - Summing the square differences and returning the square root.\n",
    "    - Calculating the euclidian distances\n",
    "    - An evaluation function to evalaute predictions\n",
    "3. Create the KNN predcit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a sample dataset\n",
    "1. Use ```make_blobs``` to create a sample set\n",
    "2. Start with 300 samples, 4 centres, 0.6 standard deviation, and random state 0\n",
    "3. Plot the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the dataset with make_blobs\n",
    "X,y = make_blobs(n_samples=300,centers=4,cluster_std=0.6,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Creating the KNN function\n",
    "Pseudocode below to help out! Note: **IT IS NOT ACTUAL CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 3, 1, 1, 1, 2, 1, 3, 3, 3, 0, 0, 0, 3, 3, 1, 2, 2, 1, 3,\n",
       "       3, 3, 3, 2, 0, 2, 2, 2, 0, 2, 2, 3, 3, 1, 1, 1, 0, 2, 1, 0, 1, 3,\n",
       "       2, 3, 3, 3, 3, 2, 1, 0, 3, 1, 3, 3, 0, 1, 2, 1, 0, 3, 0, 3, 3, 0,\n",
       "       3, 2, 0, 1, 1, 2, 0, 1, 3, 2, 2, 3, 0, 0, 3, 0, 3, 3, 2, 1, 2, 3,\n",
       "       0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 2, 1, 2, 3, 3, 2, 1, 2, 2, 3,\n",
       "       1, 1, 0, 3, 0, 0, 3, 3, 0, 0, 1, 0, 3, 1, 3, 1, 2, 0, 1, 2, 2, 0,\n",
       "       3, 0, 3, 1, 2, 1, 0, 1, 0, 1, 2, 1, 3, 0, 0, 2, 3, 2, 3, 3, 2, 1,\n",
       "       1, 3, 0, 2, 3, 3, 2, 2, 3, 2, 3, 0, 1, 3, 2, 1, 0, 1, 1, 1, 1, 3,\n",
       "       0, 3, 3, 2, 0, 3, 2, 3, 2, 1, 0, 0, 1, 2, 3, 1, 1, 0, 2, 1, 1, 1,\n",
       "       1, 2, 2, 1, 0, 3, 1, 3, 0, 2, 0, 3, 2, 0, 1, 1, 2, 0, 3, 0, 2, 3,\n",
       "       0, 2, 2, 2, 0, 1, 0, 3, 0, 0, 1, 0, 2, 3, 2, 2, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define train test split\n",
    "#X_train\n",
    "#X_test\n",
    "#y_train\n",
    "#y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_eucledian_distance(v1,v2):\n",
    "    dist = (((v1[0])-(v2[0]))**2 + ((v1[1])-(v2[1]))**2)**(1/2)\n",
    "    return dist\n",
    "\n",
    "get_eucledian_distance([1, 1], [2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_distances(X_train, X_test):\n",
    "    all_distances = []\n",
    "    for v in X_test:\n",
    "        train_test_dist = []\n",
    "        for w in X_train:\n",
    "            train_test_dist.append(get_eucledian_distance(v, w))\n",
    "        all_distances.append(train_test_dist)\n",
    "    return all_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12164120137561021,\n",
       "  0.141845859192263,\n",
       "  0.15428185537096095,\n",
       "  0.17043956983917516,\n",
       "  0.20647885307289368,\n",
       "  0.20838849631425763],\n",
       " [0.09103050850138199,\n",
       "  0.15952757114787258,\n",
       "  0.24601589349287448,\n",
       "  0.2485208116056989,\n",
       "  0.2617631052606024,\n",
       "  0.2642588666466445],\n",
       " [0.14403194363661362,\n",
       "  0.17539257513267653,\n",
       "  0.19453788566178534,\n",
       "  0.22718031854565873,\n",
       "  0.22890087793624306,\n",
       "  0.22981585458475395],\n",
       " [0.07204812487598587,\n",
       "  0.11856671367880636,\n",
       "  0.23709183165419162,\n",
       "  0.27385736923076753,\n",
       "  0.34648761616752066,\n",
       "  0.3682660436212322],\n",
       " [0.14030649114622523,\n",
       "  0.15277515979557962,\n",
       "  0.21704431524363288,\n",
       "  0.26162163860474413,\n",
       "  0.29355551369490185,\n",
       "  0.338552051896753],\n",
       " [0.2354482074378407,\n",
       "  0.2901615521893686,\n",
       "  0.32948022460250426,\n",
       "  0.4532906355403104,\n",
       "  0.5621291563488731,\n",
       "  0.590088044820537],\n",
       " [0.15106216676946363,\n",
       "  0.2593846671442474,\n",
       "  0.2688744997679549,\n",
       "  0.2940573465437763,\n",
       "  0.29858860874236726,\n",
       "  0.31349146873499817],\n",
       " [0.10837959905898893,\n",
       "  0.16328386664050618,\n",
       "  0.16667372169219224,\n",
       "  0.18154554969916833,\n",
       "  0.1890996680023027,\n",
       "  0.22859783986334542],\n",
       " [0.21929591913797458,\n",
       "  0.2335820097234421,\n",
       "  0.30040850554370724,\n",
       "  0.31367788658148454,\n",
       "  0.37623408983981294,\n",
       "  0.3777703350135647],\n",
       " [0.19715660403030585,\n",
       "  0.3337285381757963,\n",
       "  0.3521303300522766,\n",
       "  0.3534284423885839,\n",
       "  0.4535883377995529,\n",
       "  0.5092174185808075],\n",
       " [0.7070737158641641,\n",
       "  0.7153127740325551,\n",
       "  0.780840117967703,\n",
       "  0.7831908545764705,\n",
       "  0.9525595328085226,\n",
       "  0.9979770126244699],\n",
       " [0.1774097664794397,\n",
       "  0.232567453728155,\n",
       "  0.2761787936271381,\n",
       "  0.2783911973859342,\n",
       "  0.2923666300047333,\n",
       "  0.3341853268519045],\n",
       " [0.0845375327314368,\n",
       "  0.3390230048698247,\n",
       "  0.3444887580874898,\n",
       "  0.358859227404704,\n",
       "  0.39813820617448764,\n",
       "  0.4470395684390737],\n",
       " [0.09913369074862864,\n",
       "  0.17619226923841178,\n",
       "  0.23218037743963288,\n",
       "  0.2485706770733239,\n",
       "  0.26067009877711395,\n",
       "  0.2700551887986555],\n",
       " [0.31226154691346314,\n",
       "  0.3561108845634459,\n",
       "  0.3565647029049089,\n",
       "  0.3565811254269405,\n",
       "  0.3765802544216521,\n",
       "  0.39540594666928036],\n",
       " [0.33568615887827724,\n",
       "  0.36646908364513825,\n",
       "  0.3666322238762321,\n",
       "  0.39597090841286575,\n",
       "  0.4237658179959397,\n",
       "  0.4466989021767927],\n",
       " [0.14135313835754434,\n",
       "  0.16926329505676707,\n",
       "  0.29207377561354253,\n",
       "  0.29445333727146705,\n",
       "  0.34121526007758496,\n",
       "  0.3905599698999859],\n",
       " [0.20425517089771045,\n",
       "  0.2546896417361853,\n",
       "  0.27238944831475076,\n",
       "  0.283469637687466,\n",
       "  0.38064460724735905,\n",
       "  0.3999182083213041],\n",
       " [0.34628017333226374,\n",
       "  0.3607447945661021,\n",
       "  0.4238907290834023,\n",
       "  0.853779003817741,\n",
       "  0.9791989565786898,\n",
       "  0.9887376019043814],\n",
       " [0.23329901107366482,\n",
       "  0.2550575559042526,\n",
       "  0.26663458647715577,\n",
       "  0.3042778942104645,\n",
       "  0.33746043364576794,\n",
       "  0.3594559237432097],\n",
       " [0.23176964113493007,\n",
       "  0.3500210240400008,\n",
       "  0.35317442618114997,\n",
       "  0.5549537242970969,\n",
       "  0.5970144275902194,\n",
       "  0.6720608966220467],\n",
       " [0.11121557576401633,\n",
       "  0.2064552214706095,\n",
       "  0.24254861362082555,\n",
       "  0.27462518010529735,\n",
       "  0.276297205130865,\n",
       "  0.38861798294009803],\n",
       " [0.2451900374267178,\n",
       "  0.26641610901102963,\n",
       "  0.27072159457182887,\n",
       "  0.28808025510823704,\n",
       "  0.3106469351392634,\n",
       "  0.4837447198124415],\n",
       " [0.13772595335243765,\n",
       "  0.2687383880740635,\n",
       "  0.27537651408333175,\n",
       "  0.2975541172464639,\n",
       "  0.3139270032177945,\n",
       "  0.33444898665127415],\n",
       " [0.06614300198859348,\n",
       "  0.2581935548950277,\n",
       "  0.27030687785855134,\n",
       "  0.3637697685948442,\n",
       "  0.3937110296799698,\n",
       "  0.42086556716789736],\n",
       " [0.06779551853042534,\n",
       "  0.1595256964844466,\n",
       "  0.16968568905014503,\n",
       "  0.21132231417702452,\n",
       "  0.24365927360450138,\n",
       "  0.24662160920605372],\n",
       " [0.13438155466232934,\n",
       "  0.2362570173762598,\n",
       "  0.3129394113874641,\n",
       "  0.31541404756420927,\n",
       "  0.4007152745243773,\n",
       "  0.42628680164916777],\n",
       " [0.18129239796008767,\n",
       "  0.18960318942903973,\n",
       "  0.19205732692771496,\n",
       "  0.2170860446001285,\n",
       "  0.2882031421626556,\n",
       "  0.3057133130212546],\n",
       " [0.07388277981116248,\n",
       "  0.07583446216688468,\n",
       "  0.07710078231862608,\n",
       "  0.12811675085143687,\n",
       "  0.15701500678492558,\n",
       "  0.193174448541703],\n",
       " [0.07167140757183724,\n",
       "  0.3607246741858962,\n",
       "  0.40568426587812745,\n",
       "  0.410829683589229,\n",
       "  0.43584248707108975,\n",
       "  0.4365118930275485],\n",
       " [0.3006869715932635,\n",
       "  0.3107807037743197,\n",
       "  0.5753407571918973,\n",
       "  0.5771377552502271,\n",
       "  0.6369228038338732,\n",
       "  0.6533628018863806],\n",
       " [0.08200176224106409,\n",
       "  0.290559385560393,\n",
       "  0.36752250044868306,\n",
       "  0.3954111692523287,\n",
       "  0.42265043553417614,\n",
       "  0.44289041880806357],\n",
       " [0.2973378718188302,\n",
       "  0.42425760922374156,\n",
       "  0.4727588858021584,\n",
       "  0.542687026590081,\n",
       "  0.5552886276708502,\n",
       "  0.5808607356329876],\n",
       " [0.33806561945557273,\n",
       "  0.40415321049909786,\n",
       "  0.47405838887144486,\n",
       "  0.4827241930621616,\n",
       "  0.5035908046859607,\n",
       "  0.5185802801480157],\n",
       " [0.14029948427690597,\n",
       "  0.1758406829279384,\n",
       "  0.20109960378908515,\n",
       "  0.28427586516618714,\n",
       "  0.34142743846610096,\n",
       "  0.35745646679747006],\n",
       " [0.17415264084284,\n",
       "  0.20707871986318166,\n",
       "  0.22501521821089948,\n",
       "  0.23725817467170354,\n",
       "  0.23955781116859645,\n",
       "  0.24277000355277029],\n",
       " [0.29118897789684534,\n",
       "  0.3078788017785995,\n",
       "  0.40694480701906105,\n",
       "  0.459319076022751,\n",
       "  0.481140135463822,\n",
       "  0.5090865517038923],\n",
       " [0.2516987309212203,\n",
       "  0.25539460381712764,\n",
       "  0.327934588377734,\n",
       "  0.3990460363847382,\n",
       "  0.42326780122058755,\n",
       "  0.5111373034860455],\n",
       " [0.08393989496291443,\n",
       "  0.16512924626374478,\n",
       "  0.1922610226604903,\n",
       "  0.22732494581824214,\n",
       "  0.22898617465371926,\n",
       "  0.23928280395966145],\n",
       " [0.6112414603903477,\n",
       "  0.7765813235406184,\n",
       "  0.8947695188814828,\n",
       "  0.9022633834266985,\n",
       "  1.046251379415219,\n",
       "  1.0584165825130547],\n",
       " [0.05158223742120545,\n",
       "  0.05777218195329562,\n",
       "  0.2825701899303546,\n",
       "  0.47553962466432964,\n",
       "  0.5499294640642074,\n",
       "  0.5597942476100898],\n",
       " [0.08542599124087832,\n",
       "  0.0882922489864085,\n",
       "  0.1407506048039496,\n",
       "  0.21271217303793502,\n",
       "  0.2307572481212256,\n",
       "  0.24488707359030543],\n",
       " [0.022962819364211833,\n",
       "  0.08739771492910284,\n",
       "  0.132875261210306,\n",
       "  0.15256935695322776,\n",
       "  0.23795707339838607,\n",
       "  0.2661150185511488],\n",
       " [0.04322280261975316,\n",
       "  0.17463270960785313,\n",
       "  0.26167481181811164,\n",
       "  0.26325167244350745,\n",
       "  0.26735987286331697,\n",
       "  0.3111992960125466],\n",
       " [0.08480981942860107,\n",
       "  0.11244666519655903,\n",
       "  0.12516419378951849,\n",
       "  0.14978574683785112,\n",
       "  0.15642551691889328,\n",
       "  0.28217623737152187],\n",
       " [0.1715361467504035,\n",
       "  0.24400614689260144,\n",
       "  0.26139575134171833,\n",
       "  0.4188695613024074,\n",
       "  0.5842426681728324,\n",
       "  0.5985086310804131],\n",
       " [0.14604819930447696,\n",
       "  0.16540581078795083,\n",
       "  0.22960224572486443,\n",
       "  0.2600582693950197,\n",
       "  0.27066548815288094,\n",
       "  0.28096702771694687],\n",
       " [0.2790635750599121,\n",
       "  0.30737126009850585,\n",
       "  0.34721147227497823,\n",
       "  0.3757861638659746,\n",
       "  0.37601103566499416,\n",
       "  0.4095467035236592],\n",
       " [0.0196634064835308,\n",
       "  0.1705270041730838,\n",
       "  0.21486906023326577,\n",
       "  0.22209330053685014,\n",
       "  0.32734066696401226,\n",
       "  0.3755304178191965],\n",
       " [0.0831816500825267,\n",
       "  0.153323201616814,\n",
       "  0.16538718009853917,\n",
       "  0.18303442379162663,\n",
       "  0.18574417196711623,\n",
       "  0.1981690521770974],\n",
       " [0.0657803417028098,\n",
       "  0.07955078463453814,\n",
       "  0.14570059494032309,\n",
       "  0.15286389985374296,\n",
       "  0.2238952612211768,\n",
       "  0.23451641441575358],\n",
       " [0.40614876557594515,\n",
       "  0.42167896077462336,\n",
       "  0.4439591856382916,\n",
       "  0.5641593524339628,\n",
       "  0.5827276165735753,\n",
       "  0.6028635421432841],\n",
       " [0.25730896496041056,\n",
       "  0.39317184032423363,\n",
       "  0.5995858114764252,\n",
       "  0.6415750431210555,\n",
       "  0.7456754092943884,\n",
       "  0.8200616413767815],\n",
       " [0.01264241750257572,\n",
       "  0.4885788752244215,\n",
       "  0.5705876689087088,\n",
       "  0.5802202697788397,\n",
       "  0.5939636746403363,\n",
       "  0.6138946216343147],\n",
       " [0.17149737086430147,\n",
       "  0.25495048360238703,\n",
       "  0.26193284142013573,\n",
       "  0.29346218148765224,\n",
       "  0.2951254576259172,\n",
       "  0.33919715886887364],\n",
       " [0.1150909517324686,\n",
       "  0.11844863148272237,\n",
       "  0.30980566315818275,\n",
       "  0.3214050925004386,\n",
       "  0.34189466428754206,\n",
       "  0.3571068677740053],\n",
       " [0.09446930444381443,\n",
       "  0.15065641658180373,\n",
       "  0.2931585957843007,\n",
       "  0.3319786546486203,\n",
       "  0.33512538663600966,\n",
       "  0.36283041206682065],\n",
       " [0.09434691691778593,\n",
       "  0.11121428516830519,\n",
       "  0.17645276303235177,\n",
       "  0.19345632710761695,\n",
       "  0.20580239322076233,\n",
       "  0.20828929339240285],\n",
       " [0.12874176339792973,\n",
       "  0.15250766677635416,\n",
       "  0.15641004217446836,\n",
       "  0.18427806699048602,\n",
       "  0.21158051122904337,\n",
       "  0.31794719972345187],\n",
       " [0.09078366473974508,\n",
       "  0.11563195792511569,\n",
       "  0.19885919014465805,\n",
       "  0.28828710123072376,\n",
       "  0.2948401483097948,\n",
       "  0.3176277511546757]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_neighbours(dist_list, k):\n",
    "    dist_list_new = []\n",
    "    for i in dist_list:\n",
    "        i.sort()\n",
    "        i = i[0:k]\n",
    "        dist_list_new.append(i)\n",
    "    return dist_list_new\n",
    "\n",
    "select_neighbours(get_all_distances(X_train, X_test), 6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(final_n, y_train):\n",
    "    # access the index from my sliced_sorted_list\n",
    "    # get the y_train label corresponding to that index\n",
    "    # return most_common label among the list\n",
    "    for index, row in enumerate(select_neighbours(dist_list, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN function (X_train, X_test, y_train, y_test, k)\n",
    "    # given a vector, [2.5, 4.56, 2]\n",
    "    # sample X_train : [2.5,4.56] = x1,x2\n",
    "    # search with same index: y_train = 2\n",
    "    \n",
    "    # rember to do it for all X_test vectors\n",
    "    # CASE: ONE SINGLE X_train vector:\n",
    "    dist_list = []\n",
    "    for vector in X_train:\n",
    "        # result = my get_distance function\n",
    "        dist_list.append(result, index)\n",
    "    final_n = select_neighbours(dist_list, k)\n",
    "    ypred = predict(final_n, y_train)\n",
    "    score... --> using sklearn.metrics\n",
    "    or comparing 1 by 1 (ypred - ytest)\n",
    "    plot... do it inside in a separate function or outside. \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8627d1d05b21aa9e959323d79bc666a5664eb9463cf1055b74b10747d02baed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('machinelearningmodule': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}